{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20eeea7",
   "metadata": {},
   "source": [
    "# Ã‰tape 4 â€“ Optimisation des hyperparamÃ¨tres et du seuil mÃ©tier\n",
    "\n",
    "Dans ce notebook, nous allons :\n",
    "\n",
    "- Optimiser les hyperparamÃ¨tres dâ€™un modÃ¨le avec **Optuna**,\n",
    "- DÃ©finir une fonction de coÃ»t mÃ©tier (coÃ»t des FN > coÃ»t des FP),\n",
    "- Ajuster le **seuil de dÃ©cision** pour minimiser ce coÃ»t mÃ©tier.\n",
    "\n",
    "**Objectif :** Un modÃ¨le robuste, adaptÃ© aux enjeux mÃ©tier, traÃ§able avec MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084b50b",
   "metadata": {},
   "source": [
    "### 1. Chargement des bibliothÃ¨ques et des donnÃ©es\n",
    "\n",
    "Dans cette premiÃ¨re cellule, nous importons les bibliothÃ¨ques nÃ©cessaires (pandas, numpy, Optuna, XGBoost, MLflow, etc.)  \n",
    "Nous chargeons Ã©galement les jeux de donnÃ©es `X_train`, `X_test`, `y_train`, `y_test` Ã  partir de fichiers `.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = pd.read_parquet(\"../data/output/X_train.parquet\")\n",
    "X_test = pd.read_parquet(\"../data/output/X_test.parquet\")\n",
    "y_train = pd.read_parquet(\"../data/output/y_train.parquet\").squeeze()\n",
    "y_test = pd.read_parquet(\"../data/output/y_test.parquet\").squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ef56b3",
   "metadata": {},
   "source": [
    "### 2. DÃ©finition de la fonction de coÃ»t mÃ©tier\n",
    "\n",
    "Dans cette section, nous dÃ©finissons une fonction qui calcule le **coÃ»t total mÃ©tier** en pondÃ©rant diffÃ©remment les faux nÃ©gatifs (FN) et les faux positifs (FP). Ici, nous considÃ©rons quâ€™un FN coÃ»te 10 fois plus cher quâ€™un FP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4aab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_business_cost(y_true, y_pred, cost_fn=10, cost_fp=1):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return fn * cost_fn + fp * cost_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10d10a",
   "metadata": {},
   "source": [
    "### 3. DÃ©finition de lâ€™objectif pour Optuna\n",
    "\n",
    "Nous construisons une fonction `objective(trial)` qui teste plusieurs combinaisons dâ€™hyperparamÃ¨tres pour XGBoost.  \n",
    "Ã€ chaque itÃ©ration, le modÃ¨le est Ã©valuÃ© selon le coÃ»t mÃ©tier Ã  un seuil de 0.5 (Ã  optimiser plus tard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"eval_metric\": \"logloss\"\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    return compute_business_cost(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f81daa9",
   "metadata": {},
   "source": [
    "### 4. Lancement de lâ€™optimisation avec Optuna\n",
    "\n",
    "Nous lanÃ§ons lâ€™Ã©tude Optuna pour minimiser notre fonction de coÃ»t mÃ©tier.  \n",
    "Les meilleurs hyperparamÃ¨tres seront utilisÃ©s pour entraÃ®ner un modÃ¨le final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=9)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best cost:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bccb7a0",
   "metadata": {},
   "source": [
    "### 5. Optimisation du seuil mÃ©tier\n",
    "\n",
    "Une fois les meilleurs hyperparamÃ¨tres trouvÃ©s, nous testons plusieurs seuils de dÃ©cision (de 0.1 Ã  0.9)  \n",
    "afin de minimiser le coÃ»t mÃ©tier et choisir le seuil optimal pour notre classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ae89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(**study.best_params, eval_metric=\"logloss\")\n",
    "model.fit(X_train, y_train)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "costs = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (y_proba >= t).astype(int)\n",
    "    cost = compute_business_cost(y_test, y_pred)\n",
    "    costs.append(cost)\n",
    "\n",
    "optimal_threshold = thresholds[np.argmin(costs)]\n",
    "print(\"Seuil optimal :\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0ca71",
   "metadata": {},
   "source": [
    "### 6. Enregistrement du modÃ¨le et du seuil avec MLflow\n",
    "\n",
    "Nous traÃ§ons lâ€™expÃ©rimentation avec MLflow, incluant :\n",
    "- Les hyperparamÃ¨tres,\n",
    "- Le seuil optimal,\n",
    "- Le coÃ»t final,\n",
    "- Et le modÃ¨le entraÃ®nÃ©.\n",
    "\n",
    "Cela permet de garder une trace pour de futures industrialisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.models\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:../mlruns\")\n",
    "mlflow.set_experiment(\"modele_optimisation\")\n",
    "\n",
    "# Exemple de signature et input\n",
    "from mlflow.models.signature import infer_signature\n",
    "input_example = X_test.iloc[:5]\n",
    "signature = infer_signature(X_test, model.predict_proba(X_test))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"optimal_threshold\", optimal_threshold)\n",
    "    mlflow.log_metric(\"best_cost\", min(costs))\n",
    "    mlflow.sklearn.log_model(model, \"model\", signature=signature, input_example=input_example)\n",
    "    mlflow.set_tag(\"model_type\", \"XGBoost optimisÃ© avec Optuna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f38843",
   "metadata": {},
   "source": [
    "### 7. Tester plusieurs seuils et tracer la courbe coÃ»t mÃ©tier vs seuil\n",
    "\n",
    "Nous Ã©valuons les performances du modÃ¨le pour plusieurs seuils de dÃ©cision entre 0.05 et 0.95. Ã€ chaque seuil, nous transformons les probabilitÃ©s en prÃ©dictions binaires et calculons le coÃ»t mÃ©tier associÃ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thresholds = np.arange(0.05, 0.96, 0.01)\n",
    "costs = []\n",
    "\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "    cost = compute_business_cost(y_test, y_pred_thresh, cost_fn=10, cost_fp=1)\n",
    "    costs.append(cost)\n",
    "\n",
    "best_threshold = thresholds[np.argmin(costs)]\n",
    "min_cost = min(costs)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(thresholds, costs, marker='o')\n",
    "plt.axvline(best_threshold, color='red', linestyle='--', label=f'Seuil optimal = {best_threshold:.2f}')\n",
    "plt.title(\"CoÃ»t mÃ©tier en fonction du seuil de dÃ©cision\")\n",
    "plt.xlabel(\"Seuil de classification\")\n",
    "plt.ylabel(\"CoÃ»t mÃ©tier (FN*10 + FP*1)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Seuil optimal mÃ©tier : {best_threshold:.2f} avec un coÃ»t total de {min_cost:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7773fca6",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons optimisÃ© notre modÃ¨le en intÃ©grant pleinement les enjeux mÃ©tier, en particulier le coÃ»t diffÃ©renciÃ© des erreurs (FN > FP). Nous avons :\n",
    "- UtilisÃ© Optuna pour rechercher automatiquement les meilleurs hyperparamÃ¨tres dâ€™un modÃ¨le XGBoost,\n",
    "- DÃ©fini une fonction de coÃ»t personnalisÃ©e pondÃ©rant diffÃ©remment les faux positifs et faux nÃ©gatifs,\n",
    "- TestÃ© plusieurs seuils de classification entre 0.1 et 0.9,\n",
    "- TracÃ© la courbe du coÃ»t mÃ©tier en fonction du seuil,\n",
    "- IdentifiÃ© un seuil optimal Ã  {best_threshold:.2f}, minimisant le coÃ»t total des erreurs Ã  {min_cost:.0f},\n",
    "- EnregistrÃ© les expÃ©rimentations avec MLflow pour assurer leur traÃ§abilitÃ©, comparabilitÃ© et rÃ©utilisabilitÃ©.\n",
    "\n",
    "Ce travail permet de sÃ©lectionner un modÃ¨le robuste et contextualisÃ©, mieux alignÃ© avec les objectifs mÃ©tier. En remplaÃ§ant le seuil par dÃ©faut (0.5) par un seuil optimisÃ©, nous posons une base solide pour les prochaines Ã©tapes : industrialisation, suivi en production et dÃ©cision fiable en conditions rÃ©elles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc86f939",
   "metadata": {},
   "source": [
    "## Points de vigilance\n",
    "\n",
    "- âš ï¸ Ne pas garder le seuil 0.5 sans justification : il ne reflÃ¨te pas les enjeux mÃ©tier.\n",
    "- ğŸ“‰ Tracer le coÃ»t mÃ©tier vs seuil est indispensable pour bien choisir.\n",
    "- ğŸ¯ Ne pas se contenter de lâ€™AUC ou accuracy.\n",
    "- ğŸ“Š Toujours adapter les mÃ©triques et objectifs au contexte mÃ©tier.\n",
    "- ğŸ” Penser Ã  tester la robustesse du modÃ¨le sur dâ€™autres splits / seeds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
